{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MACHINE LEARNING PROJECT I\n",
    "\n",
    "#### TEAM MEMBERS: ASLI YORUSUN - ERDEM BOCUGOZ - SERIF SONER SERBEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "from data import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction,data,id_ = load_csv_data(\"train.csv\", sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_0, pred_1, pred_2, data_0, data_1, data_2, indices_0, indices_1, indices_2 = categorize_data(prediction, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, mean_x, std_x = standardize(data)\n",
    "y, tx = build_model_data(prediction, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, mean_x, std_x = process_data(data)\n",
    "y, tx = build_model_data(prediction, data)\n",
    "\n",
    "x0, mean_x0, std_x0 = process_data(data_0)\n",
    "y0, tx0 = build_model_data(pred_0,x0)\n",
    "\n",
    "x1, mean_x1, std_x1 = process_data(data_1)\n",
    "y1, tx1 = build_model_data(pred_1,x1)\n",
    "\n",
    "x2, mean_x2, std_x2 = process_data(data_2)\n",
    "y2, tx2 = build_model_data(pred_2,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent: execution time= 7.898 seconds\n",
      "Gradient Descent: RMSE Loss = 0.4123272067563234\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.1\n",
    "\n",
    "# Initialization\n",
    "initial_w = np.zeros(tx.shape[1])\n",
    "\n",
    "weights, loss = least_squares_GD(y, tx, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74434"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = predict_labels(weights,tx)\n",
    "ypred = np.where(ypred == -1, 0, ypred)\n",
    "ypred = np.squeeze(ypred)\n",
    "\n",
    "(ypred == y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent: execution time= 8.513 seconds\n",
      "Gradient Descent: RMSE Loss = 0.4123272067563234\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.1\n",
    "\n",
    "# Initialization\n",
    "initial_w = np.zeros(tx.shape[1])\n",
    "\n",
    "weights, loss = least_squares_GD(y, tx, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74497199999999997"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = predict_labels(weights,tx)\n",
    "ypred = np.where(ypred == -1, 0, ypred)\n",
    "ypred = np.squeeze(ypred)\n",
    "\n",
    "(ypred == y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least Squares: execution time= 0.086 seconds\n",
      "Least Squares: RMSE Loss = 0.41197427012456383\n"
     ]
    }
   ],
   "source": [
    "weights, loss = least_squares(y, tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "degree = 10\n",
    "split_ratio = 0.9\n",
    "lambdas = np.logspace(-10, 0, 50)\n",
    "\n",
    "lambda_ = select_hyperparameter_for_ridge_regression(x, y, degree, split_ratio, seed, lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression: RMSE Loss = 0.37604574620474157\n"
     ]
    }
   ],
   "source": [
    "tx_poly = build_poly(x,7)\n",
    "lambda_ = 0.001\n",
    "\n",
    "weight,loss = ridge_regression(y,tx_poly,0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80797200000000002"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = predict_labels(weight,tx_poly)\n",
    "ypred = np.where(ypred == -1, 0, ypred)\n",
    "ypred = np.squeeze(ypred)\n",
    "\n",
    "(ypred == y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 32\n",
    "degree = 2\n",
    "k_fold = 5\n",
    "step = 3\n",
    "lambdas = np.logspace(-10, 0, step)\n",
    "\n",
    "# Cross Validation for Ridge Regression\n",
    "lambda_ = select_hyperparameter_with_cross_validation(y, x, seed, degree, k_fold, step, lambdas)\n",
    "weights, loss = ridge_regression(y, tx, lambda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation for Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seed = 10\n",
    "degree = 4\n",
    "k_fold = 10\n",
    "step = 20\n",
    "lambdas = np.logspace(-3, 0, step)\n",
    "\n",
    "# Cross Validation for Ridge Regression\n",
    "#lambda_0 = select_hyperparameter_with_cross_validation(y0, x0, seed, degree, k_fold, step, lambdas)\n",
    "\n",
    "poly_tx0_rid = build_poly(x0, degree)\n",
    "w0, loss0 = ridge_regression(y0, poly_tx0_rid, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "degree = 12\n",
    "k_fold = 10\n",
    "step = 50\n",
    "lambdas = np.logspace(-10, 0, step)\n",
    "\n",
    "# Cross Validation for Ridge Regression\n",
    "#lambda_1 = select_hyperparameter_with_cross_validation(y1, x1, seed, degree, k_fold, step, lambdas)\n",
    "\n",
    "poly_tx1_rid = (build_poly(x1, degree))\n",
    "w1, loss1 = ridge_regression(y1, poly_tx1_rid, 0.00016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "degree = 12\n",
    "k_fold = 10\n",
    "step = 50\n",
    "lambdas = np.logspace(-10, 0, step)\n",
    "\n",
    "# Cross Validation for Ridge Regression\n",
    "#lambda_2 = select_hyperparameter_with_cross_validation(y2, x2, seed, degree, k_fold, step, lambdas)\n",
    "\n",
    "poly_tx2_rid =build_poly(x2, degree)\n",
    "w2, loss2 = ridge_regression(y2, poly_tx2_rid, 7.91e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(\"w0\",w0)\n",
    "tx_pp = poly_tx0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred0 =predict_labels(w0,tx_pp)\n",
    "y_pred1 = predict_labels(w1,poly_tx1_rid)\n",
    "y_pred2 = predict_labels(w2,poly_tx2_rid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred0 = np.where(y_pred0 == -1, 0, y_pred0)\n",
    "y_pred1 = np.where(y_pred1 == -1, 0, y_pred1)\n",
    "y_pred2 = np.where(y_pred2 == -1, 0, y_pred2)\n",
    "\n",
    "y_pred1 = np.expand_dims(y_pred1, axis=1)\n",
    "y_pred2 = np.expand_dims(y_pred2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "score0 = (np.squeeze(y_pred0) == y0).mean()\n",
    "score1 = (np.squeeze(y_pred1) == y1).mean()\n",
    "score2 = (np.squeeze(y_pred2) == y2).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score0,score1,score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test Rid Reg\n",
    "\n",
    "\n",
    "y_pred0 = predict_labels(w0,tx_pp)\n",
    "y_pred1 = predict_labels(w1,poly_tx1_rid)\n",
    "y_pred2 = predict_labels(w2,poly_tx2_rid)\n",
    "\n",
    "#y_pred0 = np.expand_dims(y_pred0, axis=1)\n",
    "y_pred1 = np.expand_dims(y_pred1, axis=1)\n",
    "y_pred2 = np.expand_dims(y_pred2, axis=1)\n",
    "\n",
    "\n",
    "rows = prediction.shape[0]\n",
    "labels = decategorize_prediction(rows, y_pred0, y_pred1, y_pred2, indices_0, indices_1, indices_2)\n",
    "\n",
    "labels = np.where(labels == -1, 0, labels)\n",
    "\n",
    "score = np.invert(np.logical_xor(prediction, np.squeeze(labels)))\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_tx1_rid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularized Logistic Regression: Loss= 0.49750322109096384\n"
     ]
    }
   ],
   "source": [
    "# init parameters\n",
    "max_iter = 1000\n",
    "gamma = 0.5\n",
    "\n",
    "weights, loss = reg_logistic_regression(y, tx,0.0001, max_iter, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72747600000000001"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = predict_labels(weights,tx)\n",
    "ypred = np.where(ypred == -1, 0, ypred)\n",
    "ypred = np.squeeze(ypred)\n",
    "\n",
    "(ypred == y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression for Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_tx0,_,_ = standardize(build_poly(x0, 2))\n",
    "poly_tx1,_,_ = standardize(build_poly(x1, 2))\n",
    "poly_tx2,_,_ = standardize(build_poly(x2, 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poly_tx0 = build_poly(x0, 2)\n",
    "poly_tx1 = build_poly(x1, 2)\n",
    "poly_tx2 = build_poly(x2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poly_tx0[np.where(poly_tx0>1000)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration=20, loss= 20.21109383661713\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erdembocugoz/Desktop/Machine Learning/MLProject1/implementations.py:229: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1 + np.exp(-t))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularized Logistic Regression: Loss= 0.3579227490534113\n"
     ]
    }
   ],
   "source": [
    "# init parameters\n",
    "max_iter = 1000\n",
    "gamma = 0.2\n",
    "w0, loss0 = reg_logistic_regression(y0, poly_tx0,0.00001,max_iter, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init parameters\n",
    "poly_tx0,_,_ = standardize(build_poly(x0, 7))\n",
    "max_iter = 200000\n",
    "gamma = 0.2\n",
    "initial_w = np.zeros((poly_tx0.shape[1], 1))\n",
    "w00, loss00 = reg_logistic_regression(y0, poly_tx0,0.00001,max_iter, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83706824937695801"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_tx0 = (build_poly(x0, 2))\n",
    "y_pred0 = predict_labels(w0,poly_tx0)\n",
    "y_pred0 = np.where(y_pred0 == -1, 0, y_pred0)\n",
    "\n",
    "score0 = (np.squeeze(y_pred0) == y0).mean()\n",
    "\n",
    "score0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularized Logistic Regression: Loss= 0.446400049846263\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.2\n",
    "max_iter  = 1000\n",
    "w1_log, loss1 = reg_logistic_regression(y1, poly_tx1,0.00001, max_iter, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79757299081811617"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1 = predict_labels(w1_log,poly_tx1)\n",
    "y_pred1 = np.where(y_pred1 == -1, 0, y_pred1)\n",
    "\n",
    "score1 = (np.squeeze(y_pred1) == y1).mean()\n",
    "\n",
    "score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularized Logistic Regression: Loss= 0.6575174195553155\n"
     ]
    }
   ],
   "source": [
    "max_iter = 1000\n",
    "gamma = 0.1\n",
    "w2, loss2 = reg_logistic_regression(y2, poly_tx2,0.00001, max_iter, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81169788952759048"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2 = predict_labels(w2,poly_tx2)\n",
    "y_pred2 = np.where(y_pred2 == -1, 0, y_pred2)\n",
    "\n",
    "score2 = (np.squeeze(y_pred2) == y2).mean()\n",
    "\n",
    "score2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81745599999999996"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_pred0 = np.expand_dims(y_pred0, axis=1)\n",
    "#y_pred1 = np.expand_dims(y_pred1, axis=1)\n",
    "rows = prediction.shape[0]\n",
    "\n",
    "#y_pred2 = np.expand_dims(y_pred2, axis=1)\n",
    "labels = decategorize_prediction(rows, y_pred0, y_pred1, y_pred2, indices_0, indices_1, indices_2)\n",
    "\n",
    "labels = np.where(labels == -1, 0, labels)\n",
    "\n",
    "score = np.invert(np.logical_xor(prediction, np.squeeze(labels)))\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Logistic Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Test Log Reg\n",
    "\n",
    "y_pred0 = predict_labels(w0,tx0)\n",
    "y_pred1 = predict_labels(w1,tx1)\n",
    "y_pred2 = predict_labels(w2,tx2)\n",
    "\n",
    "rows = prediction.shape[0]\n",
    "labels = decategorize_prediction(rows, y_pred0, y_pred1, y_pred2, indices_0, indices_1, indices_2)\n",
    "\n",
    "labels = np.where(labels == -1, 0, labels)\n",
    "\n",
    "score = prediction == np.squeeze(labels)\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf0 = Ridge(alpha=0.00001)\n",
    "clf1 = LogisticRegression(random_state=0, solver='sag')\n",
    "scores0  = cross_val_score(clf1,poly_tx0,pred_0,cv=3)\n",
    "scores0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "scores2  = cross_val_score(clf1,poly_tx2,pred_2,cv=3)\n",
    "print(scores1,scores2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores1  = cross_val_score(clf1,tx0,pred_0,cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iter = 1000\n",
    "gamma = 0.1\n",
    "lambda_ = 0.001\n",
    "\n",
    "tx_poly = build_poly(x,2)\n",
    "\n",
    "weights, loss = reg_logistic_regression(y, tx_poly, lambda_, max_iter, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = predict_labels(weights,tx)\n",
    "\n",
    "ypred = np.squeeze(ypred)\n",
    "\n",
    "(ypred == y).mean()\n",
    "round(0.73008399999999996,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularized Logistic Regression for Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iter = 1000\n",
    "gamma = 0.9\n",
    "lambda_ = 0.1\n",
    "\n",
    "w0, loss0 = reg_logistic_regression(y0, poly_tx0, lambda_,max_iter, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w1, loss1 = reg_logistic_regression(y1, tx1, lambda_,max_iter, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2, loss2 = reg_logistic_regression(y2, tx2, lambda_,max_iter, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Submission of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label,test_data,test_id_ = load_csv_data(\"test.csv\", sub_sample=False)\n",
    "\n",
    "# Split the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_0_test, pred_1_test, pred_2_test, data_0_test, data_1_test, data_2_test, indices_0_test, indices_1_test, indices_2_test = categorize_data(test_label, test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "#data_0_test,_,_ = process_data(data_0_test)\n",
    "data_1_test,_,_  = process_data(data_1_test)\n",
    "data_2_test,_,_  = process_data(data_2_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Standardize the data\n",
    "y0_test, tx0_test = build_model_data(pred_0_test,data_0_test)\n",
    "\n",
    "y1_test, tx1_test = build_model_data(pred_1_test,data_1_test)\n",
    "\n",
    "y2_test, tx2_test = build_model_data(pred_2_test,data_2_test)\n",
    "tx0_test = build_poly(data_0_test,2)\n",
    "tx1_test = build_poly(data_1_test,12)\n",
    "tx2_test = build_poly(data_2_test,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Label predictions\n",
    "y_pred0 = predict_labels(w0,tx0_test)\n",
    "y_pred1 = predict_labels(w1,tx1_test)\n",
    "y_pred2 = predict_labels(w2,tx2_test)\n",
    "\n",
    "#y_pred0 = np.expand_dims(y_pred0, axis=1)\n",
    "y_pred1 = np.expand_dims(y_pred1, axis=1)\n",
    "y_pred2 = np.expand_dims(y_pred2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare for submission\n",
    "rows = test_label.shape[0]\n",
    "labels = decategorize_prediction(rows, y_pred0, y_pred1, y_pred2, indices_0_test, indices_1_test, indices_2_test)\n",
    "\n",
    "# Create submission file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create_csv_submission(test_id_,labels,\"submission3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
