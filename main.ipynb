{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MACHINE LEARNING PROJECT I\n",
    "\n",
    "#### TEAM MEMBERS: ASLI YORUSUN - ERDEM BOCUGOZ - SERIF SONER SERBEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "from data import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction,data,id_ = load_csv_data(\"train.csv\", sub_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_0, pred_1, pred_2, data_0, data_1, data_2, indices_0, indices_1, indices_2 = categorize_data(prediction, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, mean_x, std_x = process_data(data)\n",
    "y, tx = build_model_data(prediction, x)\n",
    "\n",
    "x0, mean_x0, std_x0 = process_data(data_0)\n",
    "y0, tx0 = build_model_data(pred_0,x0)\n",
    "\n",
    "x1, mean_x1, std_x1 = process_data(data_1)\n",
    "y1, tx1 = build_model_data(pred_1,x1)\n",
    "\n",
    "x2, mean_x2, std_x2 = process_data(data_2)\n",
    "y2, tx2 = build_model_data(pred_2,x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.1\n",
    "\n",
    "# Initialization\n",
    "initial_w = np.zeros(tx.shape[1])\n",
    "\n",
    "weights, loss = least_squares_GD(y, tx, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.1\n",
    "\n",
    "# Initialization\n",
    "initial_w = np.zeros(tx.shape[1])\n",
    "\n",
    "weights, loss = least_squares_GD(y, tx, initial_w, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weights, loss = least_squares(y, tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "degree = 10\n",
    "split_ratio = 0.9\n",
    "lambdas = np.logspace(-10, 0, 50)\n",
    "\n",
    "lambda_ = select_hyperparameter_for_ridge_regression(x, y, degree, split_ratio, seed, lambdas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 32\n",
    "degree = 2\n",
    "k_fold = 5\n",
    "step = 3\n",
    "lambdas = np.logspace(-10, 0, step)\n",
    "\n",
    "# Cross Validation for Ridge Regression\n",
    "lambda_ = select_hyperparameter_with_cross_validation(y, x, seed, degree, k_fold, step, lambdas)\n",
    "weights, loss = ridge_regression(y, tx, lambda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation for Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 56\n",
    "degree0 = 4\n",
    "k_fold = 5\n",
    "step = 5\n",
    "lambdas = np.logspace(-10, 0, step)\n",
    "\n",
    "# Cross Validation for Ridge Regression\n",
    "lambda_0 = select_hyperparameter_with_cross_validation(y0, x0, seed, degree0, k_fold, step, lambdas)\n",
    "\n",
    "poly_tx0 = build_poly(x0, degree0)\n",
    "w0, loss0 = ridge_regression(y0, poly_tx0, lambda_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 56\n",
    "degree1 = 7\n",
    "k_fold = 5\n",
    "step = 5\n",
    "lambdas = np.logspace(-10, 0, step)\n",
    "\n",
    "# Cross Validation for Ridge Regression\n",
    "lambda_1 = select_hyperparameter_with_cross_validation(y1, x1, seed, degree1, k_fold, step, lambdas)\n",
    "\n",
    "poly_tx1 = build_poly(x1, degree1)\n",
    "w1, loss1 = ridge_regression(y1, poly_tx1, lambda_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 56\n",
    "degree2 = 9\n",
    "k_fold = 5\n",
    "step = 5\n",
    "lambdas = np.logspace(-10, 0, step)\n",
    "\n",
    "# Cross Validation for Ridge Regression\n",
    "lambda_2 = select_hyperparameter_with_cross_validation(y2, x2, seed, degree2, k_fold, step, lambdas)\n",
    "\n",
    "poly_tx2 = build_poly(x2, degree2)\n",
    "w2, loss2 = ridge_regression(y2, poly_tx2, lambda_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test Rid Reg\n",
    "\n",
    "y_pred0 = predict_labels(w0,poly_tx0)\n",
    "y_pred1 = predict_labels(w1,poly_tx1)\n",
    "y_pred2 = predict_labels(w2,poly_tx2)\n",
    "\n",
    "y_pred0 = np.expand_dims(y_pred0, axis=1)\n",
    "y_pred1 = np.expand_dims(y_pred1, axis=1)\n",
    "y_pred2 = np.expand_dims(y_pred2, axis=1)\n",
    "\n",
    "\n",
    "rows = prediction.shape[0]\n",
    "labels = decategorize_prediction(rows, y_pred0, y_pred1, y_pred2, indices_0, indices_1, indices_2)\n",
    "\n",
    "labels = np.where(labels == -1, 0, labels)\n",
    "\n",
    "score = np.invert(np.logical_xor(prediction, np.squeeze(labels)))\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init parameters\n",
    "max_iter = 100\n",
    "gamma = 0.1\n",
    "\n",
    "weights, loss = logistic_regression(y, tx, max_iter, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression for Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init parameters\n",
    "max_iter = 100\n",
    "gamma = 0.1\n",
    "degree0 = 2\n",
    "\n",
    "poly_tx0 = build_poly(x0, degree0)\n",
    "w0, loss0 = logistic_regression(y0, poly_tx0, max_iter, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree1 = 2\n",
    "\n",
    "poly_tx1 = build_poly(x1, degree1)\n",
    "w1, loss1 = logistic_regression(y1, poly_tx1, max_iter, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree2 = 2\n",
    "\n",
    "poly_tx2 = build_poly(x2, degree2)\n",
    "w2, loss2 = logistic_regression(y2, poly_tx2, max_iter, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Logistic Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test Log Reg\n",
    "\n",
    "y_pred0 = predict_labels(w0,tx0)\n",
    "y_pred1 = predict_labels(w1,tx1)\n",
    "y_pred2 = predict_labels(w2,tx2)\n",
    "\n",
    "rows = prediction.shape[0]\n",
    "labels = decategorize_prediction(rows, y_pred0, y_pred1, y_pred2, indices_0, indices_1, indices_2)\n",
    "\n",
    "labels = np.where(labels == -1, 0, labels)\n",
    "\n",
    "score = np.invert(np.logical_xor(prediction, np.squeeze(labels)))\n",
    "score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iter = 100\n",
    "gamma = 0.1\n",
    "lambda_ = 0.001\n",
    "\n",
    "weights, loss = reg_logistic_regression(y, tx, lambda_, max_iter, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularized Logistic Regression for Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularized Logistic Regression: Loss= 0.3709902194768535\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iter = 100\n",
    "gamma = 0.1\n",
    "lambda_ = 0.001\n",
    "degree0 = 2\n",
    "\n",
    "poly_tx0 = build_poly(x0, degree0)\n",
    "w0, loss0 = reg_logistic_regression(y0, poly_tx0, lambda_,max_iter, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularized Logistic Regression: Loss= 0.4456727532647263\n"
     ]
    }
   ],
   "source": [
    "degree1 = 2\n",
    "\n",
    "poly_tx1 = build_poly(x1, degree0)\n",
    "w1, loss1 = reg_logistic_regression(y1, poly_tx1, lambda_,max_iter, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularized Logistic Regression: Loss= 0.40229452653484055\n"
     ]
    }
   ],
   "source": [
    "degree2 = 2\n",
    "\n",
    "poly_tx2 = build_poly(x2, degree2)\n",
    "w2, loss2 = reg_logistic_regression(y2, poly_tx2, lambda_,max_iter, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Submission of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label,test_data,test_id_ = load_csv_data(\"test.csv\", sub_sample=False)\n",
    "\n",
    "# Split the data\n",
    "pred_0_test, pred_1_test, pred_2_test, data_0_test, data_1_test, data_2_test, indices_0_test, indices_1_test, indices_2_test = categorize_data(test_label, test_data)\n",
    "\n",
    "# Clean the data\n",
    "x0_test, _, _ = process_data(data_0_test)\n",
    "x1_test, _, _ = process_data(data_1_test)\n",
    "x2_test, _, _ = process_data(data_2_test)\n",
    "\n",
    "# Build tx\n",
    "#y0_test, tx0_test = build_model_data(pred_0_test,x0_test)\n",
    "#y1_test, tx1_test = build_model_data(pred_1_test,x1_test)\n",
    "#y2_test, tx2_test = build_model_data(pred_2_test,x2_test)\n",
    "\n",
    "# Build poly tx\n",
    "poly_tx0 = build_poly(x0_test, degree0)\n",
    "poly_tx1 = build_poly(x1_test, degree1)\n",
    "poly_tx2 = build_poly(x2_test, degree2)\n",
    "\n",
    "# Label predictions\n",
    "y_pred0 = predict_labels(w0, poly_tx0)\n",
    "y_pred1 = predict_labels(w1, poly_tx1)\n",
    "y_pred2 = predict_labels(w2, poly_tx2)\n",
    "\n",
    "y_pred0 = np.expand_dims(y_pred0, axis=1)\n",
    "y_pred1 = np.expand_dims(y_pred1, axis=1)\n",
    "y_pred2 = np.expand_dims(y_pred2, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Prepare for submission\n",
    "rows = test_label.shape[0]\n",
    "labels = decategorize_prediction(rows, y_pred0, y_pred1, y_pred2, indices_0_test, indices_1_test, indices_2_test)\n",
    "\n",
    "# Create submission file\n",
    "create_csv_submission(test_id_,labels,\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_file(method):\n",
    "    test_label,test_data,test_id_ = load_csv_data(\"test.csv\", sub_sample=False)\n",
    "    \n",
    "    # Split the data\n",
    "    pred_0_test, pred_1_test, pred_2_test, data_0_test, data_1_test, data_2_test, indices_0_test, indices_1_test, indices_2_test = categorize_data(test_label, test_data)\n",
    "\n",
    "    # Clean the data\n",
    "    x0_test, _, _ = process_data(data_0_test)\n",
    "    x1_test, _, _ = process_data(data_1_test)\n",
    "    x2_test, _, _ = process_data(data_2_test)\n",
    "    \n",
    "    if method ==\"ridge_regression\" or method ==\"reg_log_regression\" or method ==\"log_regression\":\n",
    "        \n",
    "        # Build poly tx\n",
    "        poly_tx0 = build_poly(x0_test, degree0)\n",
    "        poly_tx1 = build_poly(x1_test, degree1)\n",
    "        poly_tx2 = build_poly(x2_test, degree2)\n",
    "\n",
    "        # Label predictions\n",
    "        y_pred0 = predict_labels(w0, poly_tx0)\n",
    "        y_pred1 = predict_labels(w1, poly_tx1)\n",
    "        y_pred2 = predict_labels(w2, poly_tx2)\n",
    "        \n",
    "        if method ==\"ridge_regression\":\n",
    "            y_pred0 = np.expand_dims(y_pred0, axis=1)\n",
    "            y_pred1 = np.expand_dims(y_pred1, axis=1)\n",
    "            y_pred2 = np.expand_dims(y_pred2, axis=1)\n",
    "\n",
    "        # Prepare for submission\n",
    "        rows = test_label.shape[0]\n",
    "        labels = decategorize_prediction(rows, y_pred0, y_pred1, y_pred2, indices_0_test, indices_1_test, indices_2_test)\n",
    "\n",
    "        # Create submission file\n",
    "        create_csv_submission(test_id_,labels,\"submission.csv\")\n",
    "        \n",
    "    else:\n",
    "        # Build tx\n",
    "        y0_test, tx0_test = build_model_data(pred_0_test,x0_test)\n",
    "        y1_test, tx1_test = build_model_data(pred_1_test,x1_test)\n",
    "        y2_test, tx2_test = build_model_data(pred_2_test,x2_test)\n",
    "        # Label predictions\n",
    "        y_pred0 = predict_labels(w0, tx0_test)\n",
    "        y_pred1 = predict_labels(w1, tx1_test)\n",
    "        y_pred2 = predict_labels(w2, tx2_test)\n",
    "\n",
    "        # Prepare for submission\n",
    "        rows = test_label.shape[0]\n",
    "        labels = decategorize_prediction(rows, y_pred0, y_pred1, y_pred2, indices_0_test, indices_1_test, indices_2_test)\n",
    "\n",
    "        # Create submission file\n",
    "        create_csv_submission(test_id_,labels,\"submission.csv\")\n",
    "\n",
    "create_submission_file(\"reg_log_regression\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
